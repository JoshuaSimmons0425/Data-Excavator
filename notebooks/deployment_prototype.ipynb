{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76418bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def export_model(model, name):\n",
    "    filename = f\"{name}.plk\" \n",
    "    with open(filename, 'wb') as file:\n",
    "           pickle.dump(model, file)\n",
    "    print(f\"{filename} exported successfully\")\n",
    "\n",
    "def export_transformed_dataset(df, name):\n",
    "    filename = f\"{name}.pkl\"\n",
    "    df.to_pickle(filename)\n",
    "    print(f\"{filename} exported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fb438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from streamlit_jupyter import StreamlitPatcher\n",
    "\n",
    "# Enable Streamlit inside Jupyter\n",
    "StreamlitPatcher().jupyter()\n",
    "\n",
    "# Load Pretrained Model \n",
    "\n",
    "@st.cache_resource\n",
    "def load_model(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "model = load_model(\"neural_network_model2.plk\")\n",
    "\n",
    "# Load Dataset Schema (X_train_unsampled)\n",
    "\n",
    "X_train = pd.read_pickle(\"train.pkl\")  # <-- Ensure you saved it with pickle\n",
    "feature_info = {}\n",
    "\n",
    "# Extract column types directly from X_train\n",
    "for col in X_train.columns:\n",
    "    dtype = X_train[col].dtype\n",
    "    if pd.api.types.is_numeric_dtype(dtype):\n",
    "        feature_info[col] = float if dtype in [np.float32, np.float64] else int\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        feature_info[col] = \"bool\"\n",
    "    else:\n",
    "        feature_info[col] = \"category\"\n",
    "\n",
    "\n",
    "# Editable Table for Input\n",
    "\n",
    "default_data = {\n",
    "    col: [0 if dtype in [int, float] else False if dtype == \"bool\" else \"\"]\n",
    "    for col, dtype in feature_info.items()\n",
    "}\n",
    "\n",
    "input_df = pd.DataFrame(default_data, columns=feature_info.keys())\n",
    "\n",
    "st.subheader(\"Input Transaction Features\")\n",
    "edited_df = st.data_editor(input_df, num_rows=\"fixed\", key=\"input_table\")\n",
    "\n",
    "\n",
    "# Prediction\n",
    "\n",
    "if st.button(\"Predict Fraud\"):\n",
    "    row = edited_df.iloc[0:1].copy()\n",
    "\n",
    "    # Ensure category/boolean consistency with training schema\n",
    "    for col, dtype in feature_info.items():\n",
    "        if dtype == \"bool\":\n",
    "            row[col] = row[col].astype(bool)\n",
    "        elif dtype == \"category\":\n",
    "            row[col] = row[col].astype(\"category\")\n",
    "\n",
    "    prediction = model.predict(row)[0]\n",
    "    proba = None\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(row)[0][1]\n",
    "\n",
    "    st.subheader(\"Prediction Result\")\n",
    "    if prediction == 1:\n",
    "        st.error(\"This transaction is predicted as **FRAUD**.\")\n",
    "    else:\n",
    "        st.success(\"This transaction is predicted as **LEGITIMATE**.\")\n",
    "\n",
    "    if proba is not None:\n",
    "        st.write(f\"Fraud Probability: **{proba:.2f}**\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
